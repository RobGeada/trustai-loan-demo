{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from demohelpers import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from trustyai.model import Model, feature, output, feature_domain\n",
    "from trustyai.explainers import CounterfactualExplainer, LimeExplainer, SHAPExplainer\n",
    "\n",
    "import warnings\n",
    "import xgboost\n",
    "\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import show\n",
    "output_notebook()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(0)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy example\n",
    "We'll create a toy dataset with 4 well defined clusters, one per quadrant of the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=2000, n_features=2, random_state=0, centers=[(-5,-5), (5, -5),(-5,5), (5, 5)])\n",
    "plot_clusters(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll fit a K-Nearest Neighbors classifier to this toy dataset, to label each point into a cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X,y)\n",
    "\n",
    "plot_clusters(X, y, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our classifier has correctly identified that there are 4 clusters, and the classifications are are spot on. Now let's create a new point, and see where the model places it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array([[2.5, -4.0]])\n",
    "\n",
    "cluster = knn.predict(P)\n",
    "\n",
    "\n",
    "print(f\"Point P ({P[0][0]}, {P[0][1]}) is classified within cluster {cluster[0]}\")\n",
    "plot_clusters(X, y, knn, P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new points $P$ is shown in red, and the model has (correctly) placed it into Cluster 1. Lines are drawn to the centroids of each cluster, and we can see that $P$ is closest to Cluster 1 by far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counterfactuals\n",
    "Say we wanted to find a point nearby to $P$ but with a different classification. We can use a counterfactual explainer to do just that. \n",
    "\n",
    "First, we'll wrap our K-Nearest Neighbors classifier into a TrustyAI Model object, which handles all the data transmissions between Java and Python automatically, as well as tracks some attributes about our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(knn.predict, \n",
    "              feature_names=[\"X Position\", \"Y Position\"],\n",
    "              output_names=['Predicted Cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll initialize the explainer, and define some _feature domains_, that is, reasonable bounds for each feature of the input data. In our case, every points lives within the range $(-10, 10)$, so we'll use that as our x and y feature domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual = CounterfactualExplainer(steps=10_000)\n",
    "feature_domains = [\n",
    "    feature_domain((-10, 10)), #x bounds\n",
    "    feature_domain((-10, 10)), #y bounds\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can produce a counterfactual explanation, which will give us a nearby point of the desired class. Here, we pass in $P$ as the input point, and specify that our desired goal class is Class 3. This will take a second as the explainer searches for a good solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = counterfactual.explain(\n",
    "    inputs=P,\n",
    "    goal=3,\n",
    "    feature_domains=feature_domains,\n",
    "    model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what it found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_cf = explanation.proposed_features_array\n",
    "explanation.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(P_cf)\n",
    "print(f\"Point P_cf ({P_cf[0][0]},{P_cf[0][1]}) is classified within cluster {prediction[0]}\")\n",
    "plot_clusters(X, y, knn, P, P_cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new point is indeed in Cluster 3. If we look carefully, we can see that $P_{cf}$ just about as close to $P$ as is possible without becoming classified as Cluster 1; that is exactly the intended purpose of a Counterfactual \n",
    "explanation; to create a new datapoint that meets the desired goal while remaining as close to the original as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME\n",
    "Next, we'll look at a LIME explanation. LIME produces a qualitative description of how important each feature is to the output. Specifically, it looks at how small perturbations of each feature's value affects the model's output, and ranks the feature importances accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_lime = np.array([[0., -1.]])\n",
    "\n",
    "cluster = knn.predict(P_lime)\n",
    "plot_clusters(X, y, knn, P_lime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we've chosen a point $P$ right on the boundary between Cluster 0 and Cluster 1. The classifier has chosen Cluster 1, which perhaps has more outlying points closer to $P$ than Cluster 0, but this seems more or less arbitrary. We might expect that any small changes in the x-axis will likely snap the predicted classification to either side of the boundary, while any _small_ movement in the y-axis will be inconsequential. Let's see if LIME agrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime = LimeExplainer(samples=100)\n",
    "\n",
    "explanation = lime.explain(inputs=P_lime, outputs=prediction, model=model)\n",
    "explanation.as_dataframe()['Predicted Cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.plot(\"Predicted Cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIME agrees with our intuition! A change in the X position is highly influential on the classification, and thus is the most important feature. Meanwhile, small changes in the y-position are less likely to induce classification differences, and thus the y-position is less important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_shap0 = np.array([[2.5, -3.0]])\n",
    "P_shap1 = np.array([[2.5, 3.0]])\n",
    "prediction0 = knn.predict(P_shap0)\n",
    "prediction1 = knn.predict(P_shap1)\n",
    "plot_clusters(X, y, knn, [P_shap0, P_shap1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap = SHAPExplainer(background=X)\n",
    "explanation0 = shap.explain(inputs=P_shap0, \n",
    "                                 outputs=prediction0,\n",
    "                                 model=model)\n",
    "explanation0.as_html()['Predicted Cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation1 = shap.explain(inputs=P_shap1, \n",
    "                            outputs=prediction1,\n",
    "                            model=model)\n",
    "explanation1.as_html()['Predicted Cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "explanation0.plot(call_show=False)\n",
    "\n",
    "plt.subplot(1, 2, 2, sharey=plt.gca())\n",
    "explanation1.plot(call_show=False)\n",
    "\n",
    "plt.ylim(0, 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is particularly cool: \n",
    "\n",
    "1) First, the SHAP baseline starts at a predicted cluster of 1.5; the mean value of [0, 1, 2, 3]. This means at the outset, every point is equally likely to be in any cluster. \n",
    "2) For both point's explanation, the x position adds 0.5 to the prediction, halfway between cluster 1 and 3. This makes sense, a point at x=1.5 and unknown y is equally likely to be assigned to cluster 1 or 3. \n",
    "3) The y position of each point makes the final decision whether it is assigned to cluster 1 or 3. This again makes sense, as the y position disambiguates which cluster the point should be considered in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at a more real-world application. This data looks at loan applicants, and the model tries to predict whether a particular applicant will default on the loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X_train, X_test, y_train, y_test = get_loan_data()\n",
    "X_train.iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train an XGBoost Classifier to predict whether an applicant will default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "xgb_model = xgboost.XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = xgb_model.predict(X_test)\n",
    "prediction_probs = xgb_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('Test Accuracy: {:.2f}%'.format(xgb_model.score(X_test, y_test)*100))\n",
    "cmatrix = sklearn.metrics.confusion_matrix(y_test, predictions)\n",
    "print(\"\\n  Correctly Predicted Defaulted:\", cmatrix[0][0])\n",
    "print(\"  Correctly Predicted Payed:    \", cmatrix[1][1])\n",
    "print(\"Incorrectly Predicted Defaulted:\", cmatrix[1][0])\n",
    "print(\"Incorrectly Predicted Payed:    \", cmatrix[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model performs decently well, correctly predicting around 80% of test cases, and nothing in the confusion matrix looks particular concerning. \n",
    "\n",
    "Let's grab a random test applicant, and try and figure out how the model is processing that applicant. Let's call her Mrs. Twentyfive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 25\n",
    "mrs_25 = X_test.iloc[idx]\n",
    "mrs_25_prediction = prediction_probs[idx]\n",
    "\n",
    "print(mrs_25)\n",
    "if mrs_25_prediction[1]>.5:\n",
    "    print(\"\\nMrs. Twentyfive is expected ({:.2f}%) to default on the loan.\".format(mrs_25_prediction[1]*100))\n",
    "else:\n",
    "    print(\"\\nMrs. Twentyfive is expected ({:.2f}%) to pay back the loan on time.\".format(mrs_25_prediction[0]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrustyAI Setup\n",
    "We start by preparing our model to be used by TrustyAI by wrapping the prediction endpoint, `xgb_model.predict` in the TrustyAI `Model` class.\n",
    "This `Model` class takes care of all the plumbing required to run explainers on a black-box model.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trustyai_model = Model(\n",
    "    xgb_model.predict_proba,\n",
    "    dataframe_input=True, \n",
    "    feature_names=list(X_train), \n",
    "    output_names=[\"On-time\",\"Default\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME\n",
    "Let's use Lime to see what was most important to the on-time prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime = LimeExplainer(samples=100)\n",
    "\n",
    "lime_explanation = lime.explain(\n",
    "    inputs=mrs_25,\n",
    "    outputs=mrs_25_prediction, \n",
    "    model=trustyai_model)\n",
    "\n",
    "lime_explanation.as_dataframe()['On-time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explanation.plot('On-time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interpret this plot as saying that the feature `Own Realty=1` was the most important factor of our model's prediction of an on-time loan payback, followed by the total income, days employed, and days old. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP\n",
    "Now, let's use SHAP to get an exact breakdown of how the model got to Mrs. Twentyfive's prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap = SHAPExplainer(background=X_train[:100])\n",
    "\n",
    "shap_explanations = shap.explain(inputs=mrs_25, \n",
    "                                 outputs=mrs_25_prediction,\n",
    "                                 model=trustyai_model)\n",
    "\n",
    "shap_explanations.as_html()['On-time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_explanations.plot(\"On-time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows that Mrs. 25's total income and ownership of realty was massively improved the on-time probability, while the days employed reduced the probability quite significantly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counterfactuals\n",
    "Let's say the bank in question is trying to reduce their risk, and will only give loans out to applicants with a minimum 80% chance of on-time payback. We can use a counterfactual explainer to try and find out how Mrs. Twentyfive can change her application to be accepted for a loan: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unconstrained search\n",
    "First, let's run an unconstrained search, where every possible change to Mrs. Twentyfive's application is feasible. To do this, we define a very broad set of feature domains for every feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_domains = []\n",
    "for col in list(X_train):\n",
    "    feature_domains.append(\n",
    "        feature_domain(\n",
    "            (\n",
    "                0., # minimum\n",
    "                float(max(X_train[col]))) #maximum\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual = CounterfactualExplainer(steps=10_000)\n",
    "goal = .80\n",
    "\n",
    "cf_explanation = counterfactual.explain(\n",
    "    inputs=mrs_25,\n",
    "    goal=np.array([goal, 1-goal]), \n",
    "    feature_domains=feature_domains, \n",
    "    model=trustyai_model)\n",
    "cf_explanation.as_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_explanation.plot(\"On-time\")\n",
    "print(\n",
    "    \"CF Input is predicted at {:.2f}% on-time payback.\".format(\n",
    "        trustyai_model(cf_explanation.proposed_features_dataframe)[0][0]*100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the counterfactual suggests reducing her Days Employed from 10,843 to 521, which is not exactly easily possible. Furthermore, it suggests increasing her income by 58k; possible, but difficult. Let's constrain the search to more reasonable ranges:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constrained search\n",
    "To do this, we need to define the valid and feasible ranges for each feature, that is, what Mrs. Twentyfive is willing and able to change about her application. Let's take a look at her current application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll define some feature domains. Ones that are given as `None` are _fixed_ and the counterfactual search will be unable to change them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_domains = [\n",
    "    None, # # Children        \n",
    "    feature_domain((270_000., 300_000.)),    # Total Income      \n",
    "    None,    # # Family Members  \n",
    "    None,    # Male? \n",
    "    feature_domain((0., 1.)),    # Own Car?          \n",
    "    None,    # Own Realty?       \n",
    "    None,   # Partnered?        \n",
    "    feature_domain((0., 1.)),    # Working?          \n",
    "    None,    # Live with Parents?\n",
    "    feature_domain((mrs_25['Days Old'], mrs_25['Days Old']+5*365)),    # Days Old          \n",
    "    feature_domain((mrs_25['Days Employed'], mrs_25['Days Employed']+5*365)) # Days Employed     \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the new bounds, let's search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_explanation2 = counterfactual.explain(\n",
    "    inputs=mrs_25,\n",
    "    goal=np.array([goal, 1-goal]), \n",
    "    feature_domains=feature_domains, \n",
    "    model=trustyai_model)\n",
    "cf_explanation2.as_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cf_explanation2.plot()\n",
    "print(\n",
    "    \"New CF Input is predicted at {:.2f}% on-time payback.\".format(\n",
    "        trustyai_model(cf_explanation.proposed_features_dataframe)[0][0]*100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the counterfactual has found a solution where the only change neccesary is to wait until she's 1,314 days or ~3.6 years older."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation\n",
    "Alternatively, we can use the Tyrus tool to produce a dashboard of explanations automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustyai.utils.tyrus import Tyrus\n",
    "tyrus = Tyrus(\n",
    "    model=trustyai_model,\n",
    "    inputs=mrs_25,\n",
    "    outputs=mrs_25_prediction,\n",
    "    background=X_train[:100]\n",
    ")\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tyrus.run();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness metrics\n",
    "Now let's look at how model fairness and bias can be investigated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobias = pd.read_csv(\"data/income-unbiased.zip\", index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic Parity\n",
    "\n",
    "\n",
    "_Demographic Parity_ provides a measure of imbalances in positive and negative outcomes between privileged and unprivileged groups.\n",
    "\n",
    "Taking the previous data as an example, we would use Demographic Parity metrics to measure if (for instance), the `income` is predicted to be above or below $50k regardless of race or gender.\n",
    "\n",
    "\n",
    "### Statistical Parity Difference\n",
    "\n",
    "The _Statistical Parity Difference (SPD)_  is the difference in the probability of prediction between the privileged and unprivileged groups. Typically:\n",
    "\n",
    "- $SPD=0$ means that the model is behaving fairly in regards of the selected attribute (e.g. race, gender)\n",
    "- Values between $-0.1<SPD<0.1$ mean that the model is _reasonably fair_ and the score can be attributed to other factors, such as sample size.\n",
    "- An $SPD$ outside this range would be an indicator of an _unfair_ model relatively to the protected attributes.\n",
    "    - A *negative* value of statistical parity difference indicates that the unprivileged group is at a disadvantage\n",
    "    - A *positive* value indicates that the privileged group is at a disadvantage.\n",
    "\n",
    "The formal definition of $SPD$ is\n",
    "\n",
    "$$\n",
    "SPD=p(\\hat{y}=1|\\mathcal{D}_u)-p(\\hat{y}=1|\\mathcal{D}_p)\n",
    "$$\n",
    "\n",
    "where $\\hat{y}=1$ is the favorable outcome and $\\mathcal{D}_u$, $\\mathcal{D}_p$ are respectively the privileged and unpriviledge group data.\n",
    "\n",
    "\n",
    "#### Unbiased dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobias.groupby(['gender', 'income'])['income'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobias.groupby(['gender', 'income'])['income'].count().unstack().plot.bar(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustyai.metrics.fairness.group import statistical_parity_difference, \\\n",
    "    disparate_impact_ratio, average_odds_difference, average_predictive_value_difference\n",
    "\n",
    "nobias_privileged = nobias[nobias.gender == 1]\n",
    "nobias_unprivileged = nobias[nobias.gender == 0]\n",
    "favorable = output(\"income\", dtype=\"number\", value=1)\n",
    "score = statistical_parity_difference(privileged=nobias_privileged,\n",
    "                                      unprivileged=nobias_unprivileged,\n",
    "                                      favorable=[favorable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Statistical Parity Difference = {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the $SPD$ for this dataset is between the $[-0.1, 0.1]$ threshold, which classifies the model as _reasonably fair_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biased Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = pd.read_csv(\"data/income-biased.zip\", index_col=False)\n",
    "bias.groupby(['gender', 'income'])['income'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias.groupby(['gender', 'income'])['income'].count().unstack().plot.bar(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_privileged = bias[bias.gender == 1]\n",
    "bias_unprivileged = bias[bias.gender == 0]\n",
    "\n",
    "score = statistical_parity_difference(privileged=bias_privileged,\n",
    "                                      unprivileged=bias_unprivileged,\n",
    "                                      favorable=[favorable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Statistical Parity Difference = {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset, as expected, is outside the $[-0.1, 0.1]$ threshold, which classifies the model as _unfair_.\n",
    "In addiction, the negative score indicates that the unprivileged group (in our example, `gender = 0`) is the one in disadvantage for this particular outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disparate impact ratio\n",
    "\n",
    "\n",
    "Similarly to the _Statistical Parity Difference_, the _Disparate Impact Ratio (DIR)_ measures imbalances in positive outcome predictions across privliged and unpriviliged groups.\n",
    "Instead of calculating the difference, this metric calculates the ration of such selection rates.Typically:\n",
    "\n",
    "- $DIR=1$ means that the model is fair with regards to the protected attribute.\n",
    "- $0.8<DIR<1.2$ means that the model is _reasonably fair_.\n",
    "\n",
    "The formal definition of the _Disparate Impact Ratio_ is:\n",
    "\n",
    "$$\n",
    "DIR=\\dfrac{p(\\hat{y}=1|\\mathcal{D}_u)}{p(\\hat{y}=1|\\mathcal{D}_p)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unbiased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = disparate_impact_ratio(privileged=nobias_privileged,\n",
    "                               unprivileged=nobias_unprivileged,\n",
    "                                      favorable=[favorable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model Disparate Impact Ratio = {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = disparate_impact_ratio(privileged=bias_privileged,\n",
    "                               unprivileged=bias_unprivileged,\n",
    "                                      favorable=[favorable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Disparate Impact Ratio = {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Odds Difference\n",
    "\n",
    "_Average Odds Difference_ measures the difference between the True Positive Rates ($TPR$) for the privileged and unprivileged groups, and the False Positive Rates ($FPR$) for the same groups. Formally, the definition is:\n",
    "\n",
    "$$\n",
    "AOD=\\dfrac{(FPR_{u}-FPR_{p})+(TPR_{u}-TPR_{p})}{2}\n",
    "$$\n",
    "\n",
    "Typically:\n",
    "\n",
    "- A fair model will have $AOD=0$\n",
    "- A positive value indicates the model benefits the unprivileged group\n",
    "- A negative value indicates the model benefits the privileged group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = average_odds_difference(test=bias,\n",
    "                                truth=nobias,\n",
    "                                privilege_columns=[\"gender\"],\n",
    "                                privilege_values=[1], # privileged gender value, gender = 1\n",
    "                                positive_class=[1]) # positive class, income = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average Odds Difference = {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the $AOD$ indicates that the privileged group (`gender = 1`) is at an advantage in this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Predictive Value Difference\n",
    "\n",
    "The _Average Predictive Value Difference (APVD)_ measures the difference in the average accuracy of predicted values between the privileged and unprivileged groups in a dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = average_predictive_value_difference(test=bias,\n",
    "                                truth=nobias,\n",
    "                                privilege_columns=[\"gender\"],\n",
    "                                privilege_values=[1],\n",
    "                                positive_class=[1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the $APVD$ indicates that predictions over the privileged group (`gender = 1`) receive about 4.8 percentage points higher accuracy from this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trustydemo",
   "language": "python",
   "name": "trustydemo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "d5a02d5dc489c4d538b8bef3cd9147737d625f451288f0626874c379a222f279"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}